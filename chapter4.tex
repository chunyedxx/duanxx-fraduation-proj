\ifx\allfiles\undefined
\documentclass[a4paper,12.15pt,CJK,oneside]{article}
\begin{document}
%\pagestyle{plain}
\else
\fi

\chapter{研究内容}
\thispagestyle{fancy} \fancyhead[L]{\songti \wuhao
重庆师范大学硕士学位论文}\fancyhead[R]{\songti \wuhao 4~研究内容}
\section{基于多视角的本体匹配模型MuitiOM}
\subsection{问题定义}
{\songti\xiaosihao 为了缓解领域本体的异构性，本体匹配是一种有效的识别跨本体映射的技术。在继续介绍我们的方法之前，我们引入了本体映射的形式化定义。
记$0_i$和$0_j$表示两个本体，我们用四元组$({e_i},{e_j},r,\theta )$来表示一组匹配，这里$e_i$，$e_j$分别代表$0_i$和$0_j$中的实体（实体可以是本体的概念，性质等），r表示两个实体$e_i$，$e_j$之间的关系，医学本体中，r一般表示$\left\{ { \subseteq , \supseteq , \equiv } \right\}$三类关系中的一种。

\indent 在生物医学本体匹配场景中，匹配系统主要关注具有等价关系的概念映射。因此，在本文的剩余部分中，我们只考虑这些类型的映射用于生物医学本体匹配。}\\
\subsection{MuitiOM}
  {\songti\xiaosihao 现有的工作\cite{xian1,xian2,xian3}表明，采用多视角的方式可以充分的表示数据的语义信息，并提升相应任务的准确性和稳定性。受以上工作启发，我们也采用了从多个视角来描述本体匹配的过程，并针对现有方法未充利用结构信息的问题，尝试融入更多的结构信息，来提升匹配效果。
  
\begin{figure}[!h]
\centering
\includegraphics[scale=0.6]{multiom.png}
\caption{“MultiOM”模型框架}
\label{fig:muitiom}
\end{figure}

\indent MultiOM模型的框架如图\ref{fig:muitiom}，给定两个本体$0_1$和$0_2$，我们首先得到本体中的概念以以及标签，同义词，结构关系等信息，然后我们将本体匹配任务分成基于外部资源视角，基于结构视角以及基于上下文这三个视角的三个模块来实现。字典信息被用在了本体概念的归一化中，上下文信息被用在了上下文视角的模块中，第三方本体的结构信息有助于提升匹配质量，因此将第三方本体作为外部资源用在外部资源视角的模块中；最后，最后通过相互评价的组合策略来得到最终的匹配。

\indent MultiOM与统计学习类的方法不同，我们利用提取的信息，通过表示学习技术学习概念的连续向量表示，避免了统计学习类方法中特征工程的问题。与现有的基于深度学习的方法相比，我们利用第三方本体，以及本体自身的结构信息，来进一步提升匹配的效果。在MultiOM中，对同一个概念存在不同粒度的向量表示，在外部资源视角和结构视角，MultiOM分别基于TransE，TransR构建表示学习模型得到以每个概念整体为单位的向量表示，然后通过余弦相似度得到概念之间的相似度；上下文视角中，基于word2vec\cite{}训练上下文得到的本体概念中所有单词的向量表示，任意概念由多个单词的向量表示共同组成$\left\{ {{t_1},{t_2}, \ldots ,{t_n}} \right\}$，再基于这些单词表示，利用我们设计的算法计算概念之间的相似度。

1.基于上下文视角的预训练模型

基于上下文视角的模型主要基于TFIDF算法\cite{tfidf}，它也是本体匹配中计算字符串相似度的非常有效的方法之一\cite{}。根据TF-IDF算法的假设，可以将一个本体概念中所有的单词表示成一个由单词构成的词袋，每一个概念${C_i}$看作一个文档。概念所包含的单词$\left\{ {{t_1},{t_2}, \ldots ,{t_n}} \right\}$看作术语。受软TF-IDF算法\cite{}的启发，我们提出了一种基于词向量嵌入的TF-IDF 策略来计算概念的相似性，更准确的说，首先通过word2vec模型\cite{}训练对应上下文，得到词袋中所有单词的向量表示；再对丁得到每个概念中单词的表示$\left\{ {{t_1},{t_2}, \ldots ,{t_l}} \right\}$，这里$l$等于概念所包含的单词数量，基于概念中单词表示的余弦距离来得到概念对的相似度，而不是采用一般的字符串等价。相应的公式定义如下：
\[Sim({C_1},{C_2}) = \sum\limits_{i = 1} {{w_i} \cdot \mathop {\arg \max }\limits_j \cos ({t_{1i}},{t_{2j}})} \]

其中，$C_1$，$C_2$分别表示$0_1$和$0_2$中的概念，${{t_{1i}},{t_{2j}}}$表示$C_1$，$C_2$中两个单词\[{{t_{1i}},{t_{2j}}}\]的向量表示，${{w_i}}$表示${t_{1i}$在概念$C_1$中的权重，计算方式如下：
\[{w_i} = \frac{{TFIDF({t_{1i}})}}{{\sum\limits_{l = 1}^n {TFIDF({t_{1l}})} }}\]
这里$n$表示概念$C_1$所包含的单词数，$TFIDF( \cdot )$表示每个单词的TFIDF值。

\indent 因为${{t_{1i}},{t_{2j}}}$之间的余弦距离是连续的实数值，所以基于嵌入的TFIDF策略能够更好的表示概念字面的相似情况，也有助于发现更多的潜在匹配。才外，我们的软化策略取决于词嵌入的质量，可能会生成更多错误的映射，因此，我们利用预训练向量尽快覆盖本体的标记（见第4.2节）。另一方面，我们使用其他嵌入模块生成的映射来评估词汇视图模块中映射的质量（参见第3.3节）。

2.基于结构视角的预训练模型

\indent 如前所述，大多数提出的方法侧重于基于术语的特征来学习用于本体匹配的词向量，但它们并没有充分利用本体中的结构关系，所以，本节我们将从结构角度来实现本体的匹配。为了获得更多用于嵌入模型训练的候选映射，我们假设由等价字符串或其同义标签生成的映射是正确的，并定义了一个基于交叉熵的损失函数              来优化概念的向量表示。损失函数定义如下：
\[{l_{SE}} =  - \sum\limits_{({C_1},{C_2}, \equiv ,1.0) \in M} {\log {f_{SE}}({C_1},{C_2})}  - \sum\limits_{({C_1}^\prime ,{C_2}^\prime , \equiv ,1.0) \in M'} {\log {f_{SE}}({C_1}^\prime ,{C_2}^\prime )} )\]

这里$M$表示根据我们假设得到的正例候选映射$\{ ({C_1},{C_2}, \equiv ,1.0)\}$，${M'}$表示负例候选映射，我们采用新的负采用技术，来生成负例训练集${M'}$，具体如下：对每个正例${({C_1},{C_2}, \equiv ,1.0) \in M}$，根据正太分布函数得到的概率在候选集中，采用负采样策略替换$C_1$或$C_2$，得到负采样$ {({C_1}^\prime ,{C_2} , \equiv ,1.0) \in M'}$或$ {({C_1} ,{C_2}^\prime , \equiv ,1.0) \in M'}$。$ {{f_{SE}}({C_1},{C_2})}$表示由公式 定义计算概念对得分的评分函数，${C_1},{C_2} \in {R^d}$表示两个本体$0_1$和$0_2$中概念${C_1}$，${C_2}$的d维向量表示，${\left\|  \cdot  \right\|_{\rm{2}}}$ 表示向量的2范数，对于两个相似的概念${C_1}$，${C_2}$，我们希望其得分$ {{f_{SE}}({C_1},{C_2})}$尽可能大，相反，对于不相似的概念对，我们希望其得分尽可能小，基于TransE的距离转移的思想，$ {{f_{SE}}({C_1},{C_2})}$定义如下：
\[{f_{SE}}({C_1},{C_2}){\rm{ = 2}} \cdot \frac{{\rm{1}}}{{{\rm{1 + }}{e^{({{\left\| {{C_1} - {C_2}} \right\|}_2})}}}}\]

另外，我们设计的一种不同于从所有概念中抽取其替换项的均匀负采样方法的基于本体中结构关系的负采样技术大致如下，可候选概念集由所有与该概念不构成subclass\_of，part\_of关系的概念构成，并且替换时，若可候选概念集中存在与该概念构成disjoint\_with关系的概念，则优先将其采为负样本。具体如下：我们将负采样范围限制在一组候选集中，

3.基于外部资源视角的预训练模型

\begin{figure}[!h]
\centering
\includegraphics[scale=0.6]{model.png}
\caption{左：使用第三方本体连接概念的原始框架。右图：使用第三方本体连接概念的嵌入模型框架}
\label{fig:model}
\end{figure}

\indent 受文献\cite{}中方法的启发，我们采用第三方本体作为外部资源来作为连接源本体与目标本体的桥梁，现实应用中存在很多不同但存在重叠的本体，如：MA―NCI―FMA, FMA―NCI―SNOMED-CT中，与文本描述或叙词相比，第三方本体作为外部资源可以提供更多的结构信息，这有助于改进本体匹配的质量\cite{}。然而，原始的第三方本体的方法主要是基于字符串匹配，这可能无法保证匹配的质量，并且难以发现更多的相似概念。因此，我们使用表示学习技术，从多视角来解决这个问题，这里我们从外部资源视角来提升匹配的质量以及发现更多的潜在匹配。

\indent 如图\ref{ig:model}显示了第三方本体类方法的框架从字符串相等到本文的采用表示学习技术的变化。这里，我们采用$C \in {R^d}$向量来表示概念$C$，因为存在本体重叠的现象，这里我们假设存在一些概念对$({C_1},{C_2})$，以及它们在$O_1$，$O_2$中的同义词，会出现在第三方本体$O_3$中，存在这样关系的概念或同义词，我们记为$({C_1},{C_2},{C_3})$。对于不同本体中的概念，我们基于TransR的思想，不同本体的概念在不同的向量空间中，我们引入两个映射矩阵并基于这些元组对它们进行训练，以获得更多的潜在映射，损失函数定义如下；
\[{l_{RE}} =  - \sum\limits_{({C_1},{C_2},{C_3}) \in \gamma } {\log {f_{RE}}({C_1},{C_2},{C_3}))}  - \sum\limits_{({C_1}^\prime ,{C_2}^\prime ,{C_3}) \in \gamma '} {\log {f_{RE}}({C_1}^\prime ,{C_2}^\prime ,{C_3}))} )\]

\indent 这里$\gamma$表示由假设所生成的$({C_1},{C_2},{C_3})$所构成的集合，${\gamma '}$表示
   \subsection{医学本体匹配数据集}
  {\songti\xiaosihao 待完善}\\

\section{评估指标}
\setcounter{equation}{0}
\subsection{表示学习模型评估指标}
  {\songti\xiaosihao 待完善}\\
  \subsection{本体匹配评估指标}
  {\songti\xiaosihao 待完善}\\

\section{基于HORD算法的几类表示学习模型超参数优化的评估结果}
    {\songti\xiaosihao 待完善}\\
    \subsection{实验设置}
        {\songti\xiaosihao 待完善}\\
    \subsection{预测结果与分析}
        {\songti\xiaosihao 待完善}\\
\section{基于多视角的生物医学本体匹配模型--MuitiOM的评估结果}
    {\songti\xiaosihao 待完善}\\
    \subsection{实验设置}
        {\songti\xiaosihao 待完善}\\
    \subsection{本体匹配结果与分析}
        {\songti\xiaosihao 待完善}\\
\section{基于BERT模型和HORD算法对MuitiOM的改进的评估结果}
    {\songti\xiaosihao 待完善}\\
    \subsection{实验设置}
        {\songti\xiaosihao 待完善}\\
    \subsection{本体匹配结果与分析}
        {\songti\xiaosihao 待完善}\\

\ifx\allfiles\undefined
\end{document}
\fi
