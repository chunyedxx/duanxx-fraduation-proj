\ifx\allfiles\undefined
\documentclass[a4paper,12.15pt,CJK,oneside]{article}
\begin{document}
%\pagestyle{plain}
\else
\fi

\chapter{研究内容}
\thispagestyle{fancy} \fancyhead[L]{\songti \wuhao
重庆师范大学硕士学位论文}\fancyhead[R]{\songti \wuhao 4~研究内容}
\section{基于多视角的本体匹配模型MuitiOM}
\subsection{问题定义}
{\songti\xiaosihao 本体匹配是解决领域本体异构性问题的有效方法之一。为更好的阐述本文的研究内容，本文首先引入了本体匹配的形式化定义。
记$0_i$和$0_j$表示两个本体，本文用四元组$({e_i},{e_j},r,\theta )$来表示一组匹配，这里$e_i$，$e_j$分别代表$0_i$和$0_j$中的实体（实体可以是本体的概念，性质等），r表示两个实体$e_i$，$e_j$之间的关系，在多数本体中，r一般表示$\left\{ { \subseteq , \supseteq , \equiv } \right\}$三类关系中的一种。

\indent 在很多本体匹配的实际任务中，匹配系统主要关注具有等价关系的概念匹配。因此，在本文的剩余部分中，只针对需要获取等价关系的本体匹配任务，本文的模型设计也只注重挖掘领域本体中的等价关系概念对。
\subsection{MuitiOM}
  {\songti\xiaosihao 现有的工作\cite{xian1,xian2,xian3}表明，采用多视角的方式可以从不同角度获得本体更多的语义信息，并提升相应任务的准确性和稳定性。受以上工作启发，本文采用基于多视角的方法来描述本体匹配的过程，并针对现有方法未充分利用本体结构信息的问题，尝试融入更多的结构信息，来提升匹配效果。

\begin{figure}[!h]
\centering
\includegraphics[scale=0.6]{multiom.png}
\caption{“MultiOM”模型框架}
\label{fig:muitiom}
\end{figure}

\indent MultiOM模型的框架如图\ref{fig:muitiom}，给定两个本体$0_1$和$0_2$，我们首先得到本体中的概念以以及标签，同义词，结构关系等信息，然后我们将本体匹配任务分成基于外部资源视角，基于结构视角以及基于上下文这三个视角的三个模块来实现。字典信息被用在了本体概念的归一化中，上下文信息被用在了上下文视角的模块中，第三方本体的结构信息有助于提升匹配质量，因此将第三方本体作为外部资源用在外部资源视角的模块中；最后，最后通过相互评价的组合策略来得到最终的匹配。

\indent MultiOM与统计学习类的方法不同，我们利用提取的信息，通过表示学习技术学习概念的连续向量表示，避免了统计学习类方法中特征工程的问题。与现有的基于深度学习的方法相比，我们利用第三方本体，以及本体自身的结构信息，来进一步提升匹配的效果。在MultiOM中，对同一个概念存在不同粒度的向量表示，在外部资源视角和结构视角，MultiOM分别基于TransE，TransR构建表示学习模型得到以每个概念整体为单位的向量表示，然后通过余弦相似度得到概念之间的相似度；上下文视角中，基于word2vec\cite{}训练上下文得到的本体概念中所有单词的向量表示，任意概念由多个单词的向量表示共同组成$\left\{{{t_1},{t_2}, \ldots ,{t_n}} \right\}$，再基于这些单词表示，利用我们设计的算法计算概念之间的相似度。

1.基于上下文视角的预训练模型

基于上下文视角的模型主要基于TFIDF算法\cite{tfidf}，它也是本体匹配中计算字符串相似度的非常有效的方法之一\cite{}。根据TF-IDF算法的假设，可以将一个本体概念中所有的单词表示成一个由单词构成的词袋，每一个概念${C_i}$看作一个文档。概念所包含的单词$\left\{ {{t_1},{t_2}, \ldots ,{t_n}} \right\}$看作术语。受软TF-IDF算法\cite{}的启发，我们提出了一种基于词向量嵌入的TF-IDF策略来计算概念的相似性，更准确的说，首先通过word2vec模型\cite{}训练对应上下文，得到词袋中所有单词的向量表示；再对丁得到每个概念中单词的表示$\left\{ {{t_1},{t_2}, \ldots ,{t_l}} \right\}$，这里$l$等于概念所包含的单词数量，基于概念中单词表示的余弦距离来得到概念对的相似度，而不是采用一般的字符串等价。相应的公式定义如下：
\[Sim({C_1},{C_2}) = \sum\limits_{i = 1} {{w_i} \cdot \mathop {\arg \max }\limits_j \cos ({t_{1i}},{t_{2j}})} \]

其中，$C_1$，$C_2$分别表示$O_1$和$O_2$中的概念，${{t_{1i}},{t_{2j}}}$表示$C_1$，$C_2$中两个单词${{t_{1i}},{t_{2j}}}$的向量表示，${{w_i}}$表示${t_{1i}}$在概念$C_1$中的权重，计算方式如下：
\[{w_i} = \frac{{TFIDF({t_{1i}})}}{{\sum\limits_{l = 1}^n {TFIDF({t_{1l}})} }}\]
这里$n$表示概念$C_1$所包含的单词数，$TFIDF( \cdot )$表示每个单词的TFIDF值。

\indent 因为${{t_{1i}},{t_{2j}}}$之间的余弦距离是连续的实数值，所以基于嵌入的TFIDF策略能够更好的表示概念字面的相似情况，也有助于发现更多的潜在匹配。才外，我们的软化策略取决于词嵌入的质量，可能会生成更多错误的映射，因此，我们利用预训练向量尽快覆盖本体的标记（见第4.2节）。另一方面，我们使用其他嵌入模块生成的映射来评估词汇视图模块中映射的质量（参见第3.3节）。

2.基于结构视角的预训练模型

\indent 如前所述，大多数提出的方法侧重于基于术语的特征来学习用于本体匹配的词向量，但它们并没有充分利用本体中的结构关系，所以，本节我们将从结构角度来实现本体的匹配。为了获得更多用于嵌入模型训练的候选映射，我们假设由等价字符串或其同义标签生成的映射是正确的，并定义了一个基于交叉熵的损失函数来优化概念的向量表示。损失函数定义如下：
\[{l_{SE}} =  - \sum\limits_{({C_1},{C_2}, \equiv ,1.0) \in M} {\log {f_{SE}}({C_1},{C_2})}  - \sum\limits_{({C_1}^\prime ,{C_2}^\prime , \equiv ,1.0) \in M'} {\log {f_{SE}}({C_1}^\prime ,{C_2}^\prime )} )\]

这里$M$表示根据我们假设得到的正例候选映射$\{ ({C_1},{C_2}, \equiv ,1.0)\}$，${M'}$表示负例候选映射，我们采用新的负采用技术，来生成负例训练集${M'}$，具体如下：对每个正例${({C_1},{C_2}, \equiv ,1.0) \in M}$，根据正太分布函数得到的概率在候选集中，采用负采样策略替换$C_1$或$C_2$，得到负采样$ {({C_1}^\prime ,{C_2} , \equiv ,1.0) \in M'}$或$ {({C_1} ,{C_2}^\prime , \equiv ,1.0) \in M'}$。$ {{f_{SE}}({C_1},{C_2})}$表示由公式 定义计算概念对得分的评分函数，${C_1},{C_2} \in {R^d}$表示两个本体$0_1$和$0_2$中概念${C_1}$，${C_2}$的d维向量表示，${\left\|  \cdot  \right\|_{\rm{2}}}$ 表示向量的2范数，对于两个相似的概念${C_1}$，${C_2}$，我们希望其得分$ {{f_{SE}}({C_1},{C_2})}$尽可能大，相反，对于不相似的概念对，我们希望其得分尽可能小，基于TransE的距离转移的思想，$ {{f_{SE}}({C_1},{C_2})}$定义如下：
\[{f_{SE}}({C_1},{C_2}){\rm{ = 2}} \cdot \frac{{\rm{1}}}{{{\rm{1 + }}{e^{({{\left\| {{C_1} - {C_2}} \right\|}_2})}}}}\]

另外，我们设计的一种不同于从所有概念中抽取其替换项的均匀负采样方法的基于本体中结构关系的负采样技术大致如下，可候选概念集由所有与该概念不构成subclass\_of，part\_of关系的概念构成，并且替换时，若可候选概念集中存在与该概念构成disjoint\_with关系的概念，则优先将其采为负样本。例如：对于任意映射${({C_1},{C_2}, \equiv ,1.0) \in M}$，以SubClassOf关系为例，若$C_1$或$C_2$存在SubClassOf关系，即$({C_i},SubClassOf,{C_1})$或$({C_j},SubClassOf,{C_2})$，其中${C_i} \in {O_1}$，${C_j} \in {O_2}$，则负采样时需保证对$C_1$负采样时，候选集中没有$C_i$或对$C_2$负采样时候选集中没有$C_j$;同时，若$C_1$或$C_2$存在disjointwith关系,即$({C_m},disjointwith,{C_1})$或$({C_n},disjointwith,{C_2})$，则对$C_1$负采样时，优先采样$C_m$或对$C_2$负采样时，优先采样$C_n$。利用这些约束来改进负采样，我们可以得到更好的概念向量表示。

3.基于外部资源视角的预训练模型

\begin{figure}[!h]
\centering
\includegraphics[scale=0.6]{model.png}
\caption{左：使用第三方本体连接概念的原始框架。右图：使用第三方本体连接概念的嵌入模型框架}
\label{fig:model}
\end{figure}

\indent 受文献\cite{}中方法的启发，我们采用第三方本体作为外部资源来作为连接源本体与目标本体的桥梁，现实应用中存在很多不同但存在重叠的本体，如：MA―NCI―FMA, FMA―NCI―SNOMED-CT中，与文本描述或叙词相比，第三方本体作为外部资源可以提供更多的结构信息，这有助于改进本体匹配的质量\cite{}。然而，原始的第三方本体的方法主要是基于字符串匹配，这可能无法保证匹配的质量，并且难以发现更多的相似概念。因此，我们使用表示学习技术，从多视角来解决这个问题，这里我们从外部资源视角来提升匹配的质量以及发现更多的潜在匹配。

\indent 如图\ref{ig:model}显示了第三方本体类方法的框架从字符串相等到本文的采用表示学习技术的变化。这里，我们采用$C \in {R^d}$向量来表示概念$C$，因为存在本体重叠的现象，这里我们假设存在一些概念对$({C_1},{C_2})$，以及它们在$O_1$，$O_2$中的同义词，会出现在第三方本体$O_3$中，存在这样关系的概念或同义词，我们记为$({C_1},{C_2},{C_3})$。对于不同本体中的概念，我们基于TransR的思想，不同本体的概念在不同的向量空间中，我们引入两个映射矩阵并基于这些元组对它们进行训练，以获得更多的潜在映射，损失函数定义如下；
\[{l_{RE}} =  - \sum\limits_{({C_1},{C_2},{C_3}) \in \gamma } {\log {f_{RE}}({C_1},{C_2},{C_3}))}  - \sum\limits_{({C_1}^\prime ,{C_2}^\prime ,{C_3}) \in \gamma '} {\log {f_{RE}}({C_1}^\prime ,{C_2}^\prime ,{C_3}))} )\]

\indent 这里$\gamma$表示由假设所生成的$({C_1},{C_2},{C_3})$所构成的集合，${\gamma '}$表示随机替换$C_1$或者$C_2$后所构成的集合$\{ ({C_1}^\prime ,{C_2}^\prime ,{C_3})\}$，${{f_{RE}}({C_1},{C_2},{C_3})}$表示等式 所示计算投影后概念间相似度的得分函数，这里，${C_1},{C_2},{C_3} \in {R^d}$分别表示${O_1},{O_2},{O_3}$中概念${C_1},{C_2},{C_3}$的d维连续向量表示。${M_{13}}$和${M_{23}}$分别表示将概念${C_1},{C_2}$投影到第三方本体$O_3$中的映射矩阵，旨在实现将$O_1$和$O_2$中相似的概念投影到$O_3$中与他们相似的概念附近，相反，不相似的概念应该存在一定的距离，语义相反的词距离尽可能远。
\[{f_{RE}}({C_1},{C_2},{C_3}) = {\rm{2}} \cdot \frac{1}{{1 + {e^{({{\left\| {{C_1} * {M_{13}} - {C_3}} \right\|}_2} + {{\left\| {{C_2} * {M_{23}} - {C_3}} \right\|}_2})}}}}\]

\indent 两个映射矩阵非常重要，实现了不同本体间的语义关联，为了获得更好的映射矩阵，我们保持$O_3$中概念的向量表示不变，只更新两个映射矩阵以及$ {O_1},{O_2}$中概念的参数，这里需先将$O_3$中的结构关系作为数据集，利用预训练模型得到$O_3$中概念的向量表示，来保证$O_3$中概念的表示已包含其结构信息。因现有的预训练模型生成的表示稀疏性不好，无法体现$O_3$本体中的结构信息，所以，我们涉及了如下的损失函数来获得更好的概念表示：
\[{l_{RE}} =  - \sum\limits_{({C_{31}},r,{C_{32}}) \in \lambda } {\log {f_r}({C_{31}},{C_{32}}))}  - \sum\limits_{({C_1}^\prime ,r,{C_3}) \in \lambda '} {\log {f_r}({C_{31}}^\prime ,{C_{32}}^\prime ))} )\]
其中，评分函数${{f_r}}$为：
\[{f_r}({C_{31}},{C_{32}}) = 2 \cdot \frac{1}{{1 + {e^{^{({{\left\| {{C_{31}} - {C_{32}}} \right\|}_2} - a)}}}}}\]

这里$\lambda $表示由$O_3$中的结构关系三元组$({C_{31}},SubClassOf,{C_{32}})$，$({C_{31}},PartOf,{C_{32}})$构成的集合，${\lambda '}$是随机替换$ {C_{31}}$或${C_{32}}$得到的负例样本的集合，得分函数${f_r}({C_{31}},{C_{32}})$表示在关系$r$中，两个满足关系$r$的概念${C_{31}}$和${C_{32}}$的得分，${C_{31}}$，${C_{32}}$对应${C_{31}}$和${C_{32}}$的向量表示，值得注意额是这里的SubClassOf以及PartOf关系并不是等价关系，所以，我们已利用超参数$a$来控制概念向量之间的语义距离。

4.多视角模型的匹配算法

\indent 在得到不同模块的映射后，我们需要将它们组合在一起。一个简单的策略是从这些模块中收集所有映射，并用一个阈值或稳定的结合算法过滤掉它们\cite{}。尽管这种策略可以最终可以获得很多正确匹配，但它也可能引入许多错误的映射以及无法匹配到一对多，多对一或多对多的匹配。因此，我们提出了一种基于相互评估的组合策略。

\indent 简记OM-L，OM-S，OM-R表示基于上下文模块，基于结构模块和基于外部资源模块生成的对齐。具体过程如下实现。

\indent Step1：合并来自OM-S和OM-R的匹配。它们的合并结果被标记为OM-SR，其中每个映射的相似性都取OM-S和OM-R之间的相似性较大者。

\indent Step2：根据相应的阈值${\delta_1}$和${\delta_2}$选择OM-L和OM-SR的”可靠匹配”。

\indent Step3：相互评估OM-L和OM-SR的这些可靠匹配。例如，如果一个“可靠”的匹配属于OM-L，并且它在OM-SR中的相似性低于阈值${\delta_3}$，那么我们需要将其删除。相对地，如果一个可靠的匹配属于OM-SR，并且其在OM-L中的相似性低于阈值${\delta_4}$，则删除此匹配。

\indent Step3：合并来自OM-L和OM-SR的匹配，并生成最终匹配。对于同时出现在OM-L和OM-SR中的每个匹配，选择其相似性较大者。

\section{基于HORD算法对MultiOM的改进模型MultiOM+HORD}
{\songti\xiaosihao MuitiOM模型基于TransE，TransR构建表示学习模型，基于这些表示学习模型得到的概念或者关系的表示非常依赖模型的参数。为进一步获得更好的参数从而改善待匹配概念的表示并提高MuitiOM本体匹配的效果，本节考虑采用HORD算法对MuitiOM中的表示学习的超参数进行优化。

\indent HORD算法较贝叶斯类超参数优化方法，可以更加高效的同时优化整数或连续实数类超参数。MuitiOM中表示学习模型的超参数包括训练轮数（Epoch），学习率，向量维数，批次数（nbatchs）,合页损失中的$\gamma$的大小，以及负采样率，这些参数既包含整数也包含连续数，另外，模型本身的参数量较大，所以HORD 算法是适合用于实现MuitiOM模型超参数优化的方法。

\indent MuitiOM中的表示学习模型的超参数包括训练轮数（Epoch），学习率，向量维数，批次数（nbatchs）,合页损失中的$\gamma$的大小，以及负采样率。为降低参数调节的计算量，提升模型效率，本文未对以上六种参数都进行优化。首先，MuitiOM中的表示学习模型的参数规模由向量维数，以及负采样率决定，而参数旨在表示本体中概念的语义关系，我们可以根据本体所包含概念的多少，大致确定向量的维数，以及负采样率，保证可以适用于匹配任务即可。所以，MuitiOM中未对这两个参数进行调节；其次，训练轮数（Epoch）根据人工经验得到的值为1000，该参数决定了模型学习时间的长短，为保证参数优化后，可以提升MuitiOM的的效率，我们将其固定为500，通过调节剩余的三个参数，以期望以更高的效率获得当前或优于当前的匹配效果。}\\

\subsection{}
  {\songti\xiaosihao
  \begin{figure}[!h]
\centering
\includegraphics[scale=0.6]{framework.png}
\caption{本文算法框架}
\label{fig:framework}
\end{figure}

\indent 为实现MuitiOM中的表示学习模型的学习率，批次数（nbatchs）,合页损失中的$\gamma$的大小这三类参数的优化，进一步提升MuitiOM的性能，本文提出了如图\ref{fig:framework}的算法框架。因基于上下文视角的预训练模型采用训练好的词向量，并没有涉及参数优化，所以采用HORD算法对基于外部资源视角的预训练模型以及基于结构视角的模型基于学习率，批次数（nbatchs）,合页损失中的$\gamma$的大小进行参数优化。}\\
  \subsection{本体匹配评估指标}
  {\songti\xiaosihao 待完善}\\

\section{基于HORD算法的几类表示学习模型超参数优化的评估结果}
    {\songti\xiaosihao 待完善}\\
    \subsection{实验设置}
        {\songti\xiaosihao 待完善}\\
    \subsection{预测结果与分析}
        {\songti\xiaosihao 待完善}\\
\section{基于多视角的生物医学本体匹配模型--MuitiOM的评估结果}
    {\songti\xiaosihao 待完善}\\
    \subsection{实验设置}
        {\songti\xiaosihao 待完善}\\
    \subsection{本体匹配结果与分析}
        {\songti\xiaosihao 待完善}\\
\section{基于BERT模型和HORD算法对MuitiOM的改进的评估结果}
    {\songti\xiaosihao 待完善}\\
    \subsection{实验设置}
        {\songti\xiaosihao 待完善}\\
    \subsection{本体匹配结果与分析}
        {\songti\xiaosihao 待完善}\\

\ifx\allfiles\undefined
\end{document}
\fi
