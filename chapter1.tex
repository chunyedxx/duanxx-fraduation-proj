\ifx\allfiles\undefined
\documentclass[a4paper,12.15pt,CJK,oneside]{article}
\begin{document}
%\pagestyle{plain}
\else
\fi

\chapter{ 绪  ~论}
\thispagestyle{fancy} \fancyhead[L]{\songti \wuhao
重庆师范大学硕士学位论文} \fancyhead[R]{\songti \small 1 绪论}
 \songti\xiaosihao{本章首先通过介绍知识图谱与本体匹配来说明本文的研究背景及研究意义，然后阐述本文的研究内容，最后告诉读者本文的论述结构与编排。}
 
\section{研究背景}
\songti\xiaosihao{
\indent 自1989年$Tim Berners Lee$发明万维网后，人类便真正进入了信息爆炸式增长的时代。1.0时期的万维网由网页互相链接而成，但万维网中的网页内容都是通过文档呈现的。在万维网1.0时期，计算机将网页信息呈现给用户，但信息本身所包含的语义无法转化为计算机可理解的计算机语言，方便计算机进行理解，处理，比如：“唐纳德 特朗普”这一关键词，计算机只能将其识别为一个字符串，而无法理解“唐纳德 特朗普”是现任美国总统，这类问题也影响了用户从海量的信息中筛选出自己需要的信息的效率。为解决万维网1.0 中的存在的以上问题，万维网之父$Tim Berners Lee$在2001 年提出语义网，语义网是一个能够让计算机理解互联网中数据的语义信息，以及数据之间的逻辑关系，使得网页中的数据实现互相关联的数据智能网络。语义网对网页中的文档添加计算机语言的释义，计算机可对用户输入内容所包含的语义，以及网页文档内容所包含的语义，作出理解和判断，进而使得基于万维网的应用更加智能，如对网页内容进行语义搜索，处理以及整合，最终将用户感兴趣的信息以知识卡片的形式呈现给用户，进一步提升搜索的准确率。随着语义网经过20 年的发展，理论基础的不断丰富，科研成果的不断积累，语义网也逐渐被广泛应用于智能搜索，智能问答等方面。所以，对于语义网的研究，是非常重要，且有现实意义的研究。

\indent 为了构建语义网，国际万维网组织（W3C）在2007年发起了开放链接数据项目，该项目旨在将推动万维网由网页互联走向成知识互联，也有助于推动语义网的发展。项目发起后，研究者们可以对语义数据进行关联和独立发布，形成了众多的知识库，如：$Freebase$、$DBpedia$以及$YAGO$等。本体可以看作知识库的结构框架，定义了概念与概念之间层次关系，形式化的定义了同一领域内共同认可的知识。由于知识库可以分布式的发布到万维网中，多个人对同一或相关联的领域知识构建的不同知识库，在发布数据时，个人的差异会导致对同一个概念命名不相同，取值范围不同等问题，即是本体的异构问题。例如：在中国，对“土豆”这一蔬菜的叫法各不一样，在中国多数地区可被称作”土豆“，云贵地区被叫作”洋山芋“，山西称为”山药蛋“，川渝地区称作”洋芋“，对于同一个概念”土豆“有诸多的名称，这就是本体的异构问题。

\begin{figure}[!h]
\centering
\includegraphics[scale=0.6]{fig4.png}
\caption{“猪八戒”相关的百科词条}
\label{figl}
\end{figure}

\indent 本体异构问题的存在，会影响语义网中许多知识互相关联的缺失，以及导致产生一些冗余的信息。从应用层面来说，以智能搜索为例，可能会影响用户智能搜索时的准确性。为解决本体异构问题对知识库关联的影响，需要解决本体的异构问题，而本体匹配方法就是解决这一问题的可行方法，本体匹配方法就是用于寻找存在异构本体之间的语义映射关系，其中常用的做法是计算不同本体中两个概念之间的相似度，通过相似度的高低来判断两个概念之间的语义关系。$Jayant Madhavan$等人于2001 年，提出了一种有效的本体匹配系统Cupid，该方法采用基于字符串的方法，并且借助同义词词典这一外部资源，构建了这一系统。

\subsection{研究现状}
\songti\xiaosihao {
\indent 自20世纪90年代末开始，国内外学者便开始了对本体匹配的研究，历经二十多年的积累，已有大量针对本体匹配的方法。这些方法大致可分为五类：基于语言学特征的方法，基于结构特征的方法，基于外部资源的方法，基于逻辑推理的方法以及基于深度学习的方法。众多的方法中较为经典的有基于语言学特征的有$Jerome Euzenat$ 等人的$OLA$，$Fausto Oiuachiglia$ 等人的$S-Match$以及$Cupid$ 方法等；基于外部资源的$Doan$等人的$GLUE$系统；基于结构特征的$Sergey Melnik$ 等人的$SF$($Similarity Flooding$)，东南大学$P.Wang$ 等人的$Lily$系统；基于逻辑推理的$E.Jim enez-Ruiz$等人的$LogMap$($Logic-based Methods for Ontology Mapping$)方法。以上方法都主要采用了本体某一方面（语言学，结构，外部资源，逻辑推理）的元素之间的相似性，所以导致了以上方法适用的场景比较有限，比如：若两个本体之间的结构关系比较明确，则采用基于结构特征的$SF$f方法效果会比较好，而采用基于语言学特征的$OLA$方法效果则会不好。所以就产生了综合了多种特征的方法，比如：$AML$($Agreement Maker Light$)系统, 蒙特利尔大学的$YAM++$ 的方法，清华大学$J.Li$ 等人的$RiMOM$系统，以及2018年的$M. Zhao$ 等人的$FCA-Map$方法。 这些方法都能在一些的场景下取得很好的效果，但对于给定的实际任务来说，寻找合适的特征便是一项耗费时间的工作，这一点在$Cheatham and Hitzler （2013）$的工作中已经得到验证：

而深度学习的特点就是能够自动学习特征，自动进行特征选择，所以深度学习可以克服基于特征工程的方法所带来的昂贵的时间代价问题，这一点在$Prodromos Kolyvakis$的$DeepAlignment$，$SCBOW$，以及$Ernesto Jim$的工作中，已经得到证明，采用语义嵌入表示的方式，利用大量语义信息，借助低维实值向量，来对实体，关系进行表示，取得了很好的效果。但这三篇工作，都只利用了上下文，已经词典的信息，而没有很好的考虑到本体之间的结构层次关系，如果加上有效的结构约束，则才能使得匹配的整体思路更加完整。这一点，也在$Ernesto Jim$的文章最后被提及。}


 \section{研究意义}
 \songti\xiaosihao{当下，深度学习技术已经被验证对本体匹配任务是非常有效的技术手段，而利用深度学习技术进行本体匹配研究的工作还不多，且已有的三篇工作中，并没有能够很好的利用本体与本体之间的结构关系，所以本文从深度学习的角度，充分考虑本体之间的结构关系，开展对本体匹配的研究，来丰富采用深度学习技术解决本体匹配任务的研究。

\indent 但深度学习的运用，自然需要解决对本体中实体与关系的表示问题，所以本文结合知识图谱表示学习方法来作为实现实体或关系的嵌入方法，从深度学习角度，利用表示学习思想和方法，为本体匹配的进一步研究供新的思路与方法。

\indent 虽然深度学习技术十分有效，但对于模型的参数的调节却是一项耗时耗力的工作，参数对模型结果的影响不言而喻，本文中，表示学习模型效果的好坏直接影响着后续匹配的效果，所以本文采用了带有全局思想的黑箱优化算法--HORD算法来实现对模型超参数的半自动优化，来提升最终的匹配效果，也为几类表示学习模型的超参数调节提供统一可行的框架。}

\section{研究内容}
\setcounter{equation}{0}
\songti\xiaosihao{\indent 本文的主要研究内容包含以下四个方面：
\indent 利用表示学习中基于距离的建模思想及其方法，并且充分考虑本体自身的结构信息，以及上下文信息，将结构信息作为新的模型约束，上下文信息来获得更好的嵌入表示，来搭建新的本体匹配模型。

\indent 将带有全局思想的黑箱优化算法--HORD算法，用以对几类表示学习模型的超参数半自动优化。表示学习模型针对不同的数据集进行训练时，需要手动调节模型的超参数，这是一项比较耗时的工作，并且得到的最终效果也是一个“经验值”，所以采用带有全局思想的HORD算法对表示学习模型的超参数进一步调节，从而进一步提升表示学习的效果。

\indent 在内容2的基础上，进一步针对内容2中模型的上下文信息不足的问题，进一步改进，采用效果更好的BERT模型，作为本体匹配模型的预训练嵌入表示，并且将已经在内容1 中验证有效的HORD算法，来进一步优化模型的超参数，提升本体匹配模型的效果。

\indent 在基准数据集上，利用常用的评估指标对模型效果进行评估，并将本文中的模型的效果与其他较新的模型结果进行对比，分析，验证本文工作的有效性。}

\section{文章结构安排}
\setcounter{equation}{0}
\songti\xiaosihao {本文共分为六个章节，本文的结构编排如下：

第一章：一方面，简述本文的研究背景，介绍知识图谱，引出本体匹配，并介绍知识图谱相关概念；另一方面，从理论与实际应用角度阐述本文的研究意义，并对本文的具体研究内容进行简述。

第二章：对本体匹配的相关工作，方法从传统的方法，以及基于深度学习的方法两个方面对已有工作进行综述，总结。

第三章：详细介绍本文的具体研究内容，首先对本章的预备知识，HORD算法，几类表示学习模型，BERT模型进行说明；提出基于多视角的生物医学本体匹配模型，然后介绍基于HORD算法的几类表示学习模型超参数优化方法，最后，阐述基于BERT模型和HORD算法对MuitiOM的改进工作。

第四章：利用常用的模型评价指标，标准数据集，在上一章基础上，对三个研究内容进行实验评估，并将实验结果与其他方法作比较，进行分析。

第五章：对本文的工作进行总结，并对未来工作进行展望。

第六章：本文的相关参考文献。}
\ifx\allfiles\undefined
\end{document}
\fi
% ----------------------------------------------------------------
