\ifx\allfiles\undefined
\documentclass[a4paper,12.15pt,CJK,oneside]{article}
\begin{document}
%\pagestyle{plain}
\else
\fi

\chapter{ 绪  ~论}
\thispagestyle{fancy} \fancyhead[L]{\songti \wuhao
重庆师范大学硕士学位论文} \fancyhead[R]{\songti \small 1 绪论}
 \songti\xiaosihao{本章首先通过介绍知识图谱与本体匹配来说明本文的研究背景及研究意义，然后阐述本文的研究内容，最后告诉读者本文的论述结构与编排。}

\section{研究背景}
\songti\xiaosihao{
\indent 自1989年Tim Berners Lee发明万维网后，人类便真正进入了信息爆炸式增长的时代。1.0时期的万维网由网页互相链接而成，但万维网中的网页内容都是通过文档呈现的。在万维网1.0时期，计算机将网页信息呈现给用户，但信息本身所包含的语义无法转化为计算机可理解的计算机语言，方便计算机进行理解，处理，比如：“唐纳德 特朗普”这一关键词，计算机只能将其识别为一个字符串，而无法理解“唐纳德 特朗普”是现任美国总统，这类问题也影响了用户从海量的信息中筛选出自己需要的信息的效率。为解决万维网1.0中的存在的以上问题，万维网之父Tim Berners Lee在2001年提出语义网，语义网是一个能够让计算机理解互联网中数据的语义信息，以及数据之间的逻辑关系，使得网页中的数据实现互相关联的数据智能网络。语义网对网页中的文档添加计算机语言的释义，计算机可对用户输入内容所包含的语义，以及网页文档内容所包含的语义，作出理解和判断，进而使得基于万维网的应用更加智能，如对网页内容进行语义搜索，处理以及整合，最终将用户感兴趣的信息以知识卡片的形式呈现给用户，进一步提升搜索的准确率。随着语义网经过20年的发展，理论基础的不断丰富，科研成果的不断积累，语义网也逐渐被广泛应用于智能搜索，智能问答等方面。所以，对于语义网的研究，是非常重要，且有现实意义的研究。

\begin{figure}[!h]
\centering
\includegraphics[scale=0.4]{patato.png}
\caption{“土豆”及其别名}
\label{fig:tudou}
\end{figure}

\indent 为了构建语义网，国际万维网组织（W3C）在2007年发起了开放链接数据项目\footnote{https://www.w3.org/wiki/SweoIG/TaskForces/CommunityProjects/LinkingOpenData}，该项目旨在将推动万维网由网页互联走向成知识互联，也有助于推动语义网的发展。项目发起后，研究者们可以对语义数据进行关联和独立发布，形成了众多的知识库，如：Freebase\footnote{https://developers.google.com/freebase/}、DBpedia\footnote{http://wiki.dbpedia.org/}以及YAGO\footnote{https://www.mpi-inf.mpg.de/departments/databases-and-information-systems/research/yago-naga/
yago/}等。本体可以看作知识库的结构框架，定义了概念与概念之间层次关系，形式化的定义了同一领域内共同认可的知识。由于知识库可以分布式的发布到万维网中，多个人对同一或相关联的领域知识构建的不同知识库，在发布数据时，个人的差异会导致对同一个概念命名不相同，取值范围不同等问题，即是本体的异构问题。例如：如图\ref{fig:tudou} 在中国，对“土豆”这一蔬菜的叫法各不一样，在中国多数地区可被称作”土豆“，云贵地区被叫作”洋山芋“，山西称为”山药蛋“，川渝地区称作”洋芋“，对于同一个概念”土豆“有诸多的名称，这就是本体的异构问题。

\subsection{研究现状}
\songti\xiaosihao {
\indent 本体异构问题，在两个本体合并过程中，会导致语义网中许多知识互相关联的缺失并且产生冗余信息。若消除本体异构的问题，以智能搜索为例，则可以提升检索的准确率，举例说明：如图\ref{fig:BAT}我们知道百度，阿里和腾讯，但是从事文学相关领域的工作者可能不知道“BAT”就代表这三所互联网公司，这是不同领域（可以理解为不同本体）对同一概念的命名不同导致的，也就导致了关联的缺失，而现在的互联网可以消除这种本体异构问题，搜素引擎可以告诉你，“BAT”就是中国互联网公司百度公司（Baidu）、阿里巴巴集团（Alibaba）、腾讯公司（Tencent）三大互联网公司首字母的缩写。本体异构问题是知识库关联过程中需要解决的重要问题，而本体匹配方法就是解决这一问题的方法之一，本体匹配方法就是用于寻找存在异构本体之间的语义映射关系，其中常用的做法是计算不同本体中两个概念之间的相似度，通过相似度的高低来判断两个概念之间的语义关系。

\begin{figure}[!h]
\centering
\includegraphics[scale=0.6]{BAT.png}
\caption{“BAT”的含义}
\label{fig:BAT}
\end{figure}

\indent 为解决本体异构的问题，自20世纪90年代末开始，国内外学者便开始了对本体匹配的研究，历经二十多年的积累，已有大量针对本体匹配的方法。这些方法大致可分为两类：基于统计学习的方法和基于深度学习的方法。基于统计学习的方法有较为经典的Jerome Euzenat等人针对OWL-Lite表示的本体提出的综合利用字符串距离和词汇距离的OLA\cite{ola}，Jayant Madhavan等人提出的使用了字符串和词典两种方式的Schema匹配工具Cupid\cite{cupid}；Doan等人利用实例信息作为外部资源采用概念间联合概率分布计算相似度的GLUE系统\cite{glue}；利用了结构特征的Sergey Melnik等人提出的利用图模型的匹配算法SF(Similarity Flooding)\cite{sf}，利用逻辑推理的E.Jim enez-Ruiz等人的采用了Horn命题逻辑表示本体层次结构与匹配的LogMap(Logic-based Methods for Ontology Mapping) 方法\cite{lm}。以上方法都是只利用了本体某一方面（语言学特征，结构特征等）特征的匹配方法，除此之外，还有综合利用多种特征的本体匹配系统。比如：综合利用基于语言学特征与结构特征的基础匹配器，最后将二者线性加权求和的AML(Agreement Maker Light)系统\cite{aml}, 蒙特利尔大学的在语言学特征模型得到的匹配的基础上，结合结构特征提高匹配质量的YAM++的方法\cite{yam}，以及2018年的M.Zhao等人的综合了基于语言学特征，结构特征，以及逻辑推理的FCA-Map方法\cite{fca}等。虽然这些方法在其给定的，与其方法特点相对应的数据集中可以取得比较好的效果，但在实际的本体匹配任务中，对于特征工程类本体匹配方法，人工的特征工程很难找到合适的特征，常常是非常耗时的工作\cite{deep}。而基于深度学习的本体匹配方法，通常不需要对特征进行人工选择，而是通过对模型参数的调节，实现模型自动选择特征，Prodromos Kolyvakis\cite{deep}的DeepAlignment，SCBOW\cite{scbow}，以及Ernesto Jim\cite{ontoemma}的Ontoemma的基于深度学习的本体匹配方法不仅证明了模型自行选择特征是有效的，并且可以获得更适合的特征，提升本体匹配的效果。以上三种是较为典型的基于深度学习类本体匹配方法，这类方法大多借助字典或者上下文信息作为外部资源，借助深度学习模型，得到单词的词嵌入表示，再利用单词的词嵌入得到概念的向量表示，最终利用向量的语义相似度来判断概念的相似度。

\indent 虽然基于深度学习的本体匹配方法相比人工特征的方法，可以学到更加合适的特征，提升本体匹配的效果。但是，词向量无法准确表示概念的语义，而本体本身的结构信息也包含了大量的语义，忽略掉本体本身的结构信息会直接影响本体匹配方法的性能。以医学本体FMA\footnote{http://owlapi.sourceforge.net/}与NCI\footnote{http://owlapi.sourceforge.net/}的匹配为例，”Blood Capillary“（NCI中概念）与”Capillary“（FMA中概念）在以上几种基于深度学习本体匹配方法中会被认为是正确匹配（百度翻译也会翻译为同义词”毛细血管“），若考虑结构信息，NCI本体中包含关系”Blood Capillary subclass\_of Capillary“，即是“儿子”与”父亲“的关系，则可避免这样的错误。另一方面，基于深度学习的本体匹配方法的性能依赖于模型所学特征，其常常使用随机向量或者基于文本的预训练模型来提取待匹配概念的特征或表示。但随机向量或者文本预训练模型得到的概念向量表示通常会将概念做为一个独立的单元忽略了概念之间的关联关系。 这导致其表示不符合概念在知识图谱\footnote{https://www.google.com/intl/bn/insidesearch/features/search/knowledge.html}中的表示。近年来知识图谱表示学习模型展现了其在知识表示的优势，但现有的工作证明，在知识图谱表示模型中，概念或者关系的表示非常依赖模型的参数。如何在知识图谱表示学习中找到更好的参数从而改善待匹配概念的表示并提高本体匹配的效果也是需要克服的问题。


\section{研究内容}
\setcounter{equation}{0}
\songti\xiaosihao{
\begin{figure}[!h]
\centering
\includegraphics[scale=0.6]{framework.png}
\caption{本文算法框架}
\label{fig:framework}
\end{figure}

\indent 本文针对以上现有基于深度学习的本体匹配方法存在的问题，设计了如图\ref{fig:framework}所示的模型框架，该模型分为两个子模型，第一部分是基于深度学习的多视角本体匹配模型MuitiOM，MuitiOM融入了同义词，上下文以及第三方本体的信息，由外部资源视角的预训练模型，结构视角的预训练模型，以及融入上下文视角的预训练模型组成，通过将由${O_{\rm{1}}}$和${O_{\rm{2}}}$两个本体中获得的概念对分别输入不同视角的模型中，经由模型处理，得到概念的向量表示，再利用多视角匹配算法基于概念对的相似度来筛选匹配。第二部分是在MuitiOM的基础上，在外部资源视角的预训练模型，结构视角的预训练模型中分别加入带有全局思想的HORD算法，提出了采用HORD算法优化MuitiOM中外部资源视角的预训练模型和结构视角的预训练模型的MuitiOM+HORD的模型框架，来改进模型最终MuitiOM模型的性能。所以，本文的主要工作包含以下三个方面：

\indent 1.为了更准确的表示知识图谱中的概念，提升本体匹配的性能，本文提出了一个利用多视角的方法来提取概念信息，该方法从概念的文本、概念在多个本体间的映射和概念所处的本体本身三个视角来计算概念的表示。相比与现有深度学习的匹配方法只关注本体概念的字面含义，MuitiOM从多个视角来获取概念的表示，相对现有深度学习的方法，多视角可以从不同维度对待匹配的概念对进行计算，进而提升了本体匹配的性能。

\indent 2.MultiOM使用了多个表示学习模型通过多个视角来提取待匹配概念的特征，在该方法下人多个预训练模型得到的概念表示将影响本体匹配的性能，而预训练模型学习的概念表示对参数非常敏感。为解决该问题，本文首次将黑箱优化和知识图谱表示学习进行结合。在该方法下，通过黑箱优化HORD算法自动调节多个表示学习模型的参数，进一步使得多视角表示学习模型可以学习更好的特征。

\indent 3.在基准数据集上，利用常用的评估指标对模型效果进行评估，并将本文中的模型的效果与其他较新的模型结果进行对比，分析，验证本文工作的有效性。}

\section{文章结构安排}
\setcounter{equation}{0}
\songti\xiaosihao {本文共分为六个章节，本文的结构编排如下：

第一章：一方面，简述本文的研究背景，介绍语义网，进而通过语义网中本体的异构问题，引出本体匹配；另一方面，介绍本体匹配研究的现状，根据目前的相关研究存在的问题，阐述本文的研究内容，并对本文的具体研究内容进行简述。

第二章：对本体匹配的相关工作，方法从基于特征工程类方法，以及基于深度学习的方法两个方面对已有工作进行综述，总结。
第三章：对本文研究内容所涉及的先验知识：HORD算法，表示学习及几类表示学习模型，BERT模型进行介绍。

第四章：介绍本文提出的提出基于多视角的生物医学本体匹配模型，然后介绍基于HORD算法的几类表示学习模型超参数优化方法，阐述基于BERT模型和HORD算法对MuitiOM的改进工作。

第五章：对本文的工作进行总结，并对未来工作进行展望。

第六章：本文的相关参考文献。}
\ifx\allfiles\undefined
\end{document}
\fi
% ----------------------------------------------------------------
