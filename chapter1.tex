\ifx\allfiles\undefined
\documentclass[a4paper,12.15pt,CJK,oneside]{article}
\begin{document}
%\pagestyle{plain}
\else
\fi

\chapter{ 绪  ~论}
\thispagestyle{fancy} \fancyhead[L]{\songti \wuhao
重庆师范大学硕士学位论文} \fancyhead[R]{\songti \small 1 绪论}
 \songti\xiaosihao{本章首先通过介绍知识图谱与本体匹配来说明本文的研究背景及研究意义，然后阐述本文的研究内容，最后告诉读者本文的论述结构与编排。}

\section{研究背景}
\songti\xiaosihao{
\indent 自1989年$Tim Berners Lee$发明万维网后，人类便真正进入了信息爆炸式增长的时代。1.0时期的万维网由网页互相链接而成，但万维网中的网页内容都是通过文档呈现的。在万维网1.0时期，计算机将网页信息呈现给用户，但信息本身所包含的语义无法转化为计算机可理解的计算机语言，方便计算机进行理解，处理，比如：“唐纳德 特朗普”这一关键词，计算机只能将其识别为一个字符串，而无法理解“唐纳德 特朗普”是现任美国总统，这类问题也影响了用户从海量的信息中筛选出自己需要的信息的效率。为解决万维网1.0 中的存在的以上问题，万维网之父$Tim Berners Lee$在2001 年提出语义网，语义网是一个能够让计算机理解互联网中数据的语义信息，以及数据之间的逻辑关系，使得网页中的数据实现互相关联的数据智能网络。语义网对网页中的文档添加计算机语言的释义，计算机可对用户输入内容所包含的语义，以及网页文档内容所包含的语义，作出理解和判断，进而使得基于万维网的应用更加智能，如对网页内容进行语义搜索，处理以及整合，最终将用户感兴趣的信息以知识卡片的形式呈现给用户，进一步提升搜索的准确率。随着语义网经过20 年的发展，理论基础的不断丰富，科研成果的不断积累，语义网也逐渐被广泛应用于智能搜索，智能问答等方面。所以，对于语义网的研究，是非常重要，且有现实意义的研究。

\indent 为了构建语义网，国际万维网组织（W3C）在2007年发起了开放链接数据项目，该项目旨在将推动万维网由网页互联走向成知识互联，也有助于推动语义网的发展。项目发起后，研究者们可以对语义数据进行关联和独立发布，形成了众多的知识库，如：$Freebase$、$DBpedia$以及$YAGO$等。本体可以看作知识库的结构框架，定义了概念与概念之间层次关系，形式化的定义了同一领域内共同认可的知识。由于知识库可以分布式的发布到万维网中，多个人对同一或相关联的领域知识构建的不同知识库，在发布数据时，个人的差异会导致对同一个概念命名不相同，取值范围不同等问题，即是本体的异构问题。例如：在中国，对“土豆”这一蔬菜的叫法各不一样，在中国多数地区可被称作”土豆“，云贵地区被叫作”洋山芋“，山西称为”山药蛋“，川渝地区称作”洋芋“，对于同一个概念”土豆“有诸多的名称，这就是本体的异构问题。

\begin{figure}[!h]
\centering
\includegraphics[scale=0.6]{fig4.png}
\caption{“猪八戒”相关的百科词条}
\label{figl}
\end{figure}



\subsection{研究现状}
\songti\xiaosihao {
\indent 本体异构问题，在两个本体合并过程中，会导致语义网中许多知识互相关联的缺失并且产生冗余信息。若消除本体异构的问题，以智能搜索为例，则可以提升检索的准确率，举例说明：我们知道百度，阿里和腾讯，但是从事文学相关领域的工作者可能不知道“BAT”就代表这三所互联网公司，这是不同领域（可以理解为不同本体）对同一概念的命名不同导致的，也就导致了关联的缺失，而现在的互联网可以消除这种本体异构问题，搜素引擎可以告诉你，“BAT”就是中国互联网公司百度公司（Baidu）、阿里巴巴集团（Alibaba）、腾讯公司（Tencent）三大互联网公司首字母的缩写。本体异构问题是知识库关联过程中需要解决的重要问题，而本体匹配方法就是解决这一问题的方法之一，本体匹配方法就是用于寻找存在异构本体之间的语义映射关系，其中常用的做法是计算不同本体中两个概念之间的相似度，通过相似度的高低来判断两个概念之间的语义关系。

\indent 为解决本体异构的问题，自20世纪90年代末开始，国内外学者便开始了对本体匹配的研究，历经二十多年的积累，已有大量针对本体匹配的方法。这些方法大致可分为两类：基于特征工程的方法和基于深度学习的方法。基于特征工程的方法包括基于语言学特征的方法，基于结构特征的方法，基于外部资源的方法，基于逻辑推理的方法以及基于深度学习的方法。基于语言学特征的方法中较为经典的有$Jerome Euzenat$ 等人针对OWL-Lite表示的本体提出的综合利用字符串距离和词汇距离的$OLA$\cite{OLA}，$Jayant Madhavan$ 等人提出的使用了字符串和词典两种方式的Schema 匹配工具$Cupid$ \cite{cupid}等；基于外部资源的$Doan$ 等人利用实例信息采用概念间联合概率分布计算相似度的$GLUE$ 系统\cite{glue}；基于结构特征的$Sergey Melnik$ 等人的利用图模型的匹配算法$SF$($Similarity Flooding$)\cite{SM}，基于逻辑推理的$E.Jim enez-Ruiz$ 等人的采用了Horn命题逻辑表示本体层次结构与匹配的$LogMap$($Logic-based Methods for Ontology Mapping$)方法\cite{LM}。除此之外，还有综合利用多种特征的本体匹配系统，比如：综合利用基于语言学特征与结构特征的基础匹配器，最后将二者线性加权求和的$AML$($Agreement Maker Light$) 系统\cite{AML}, 蒙特利尔大学的在基于语言学特征模型得到的匹配的基础上，结合结构特征提高匹配质量的$YAM++$ 的方法\cite{YAM}，以及2018 年的$M.Zhao$等人的综合了基于语言学特征，结构特征，以及逻辑推理的$FCA-Map$ 方法\cite{FMA}等。虽然这些方法在其给定的，与其方法特点相对应的数据集中可以取得比较好的效果，但在实际的本体匹配任务中，对于特征工程类本体匹配方法，人工的特征工程很难找到合适的特征，常常是非常耗时的工作\cite{DS}。而基于深度学习的本体匹配方法，通常不需要对特征进行人工选择，而是通过对模型参数的调节，实现模型自动选择特征，$Prodromos Kolyvakis$\cite{PK} 的$DeepAlignment$，$SCBOW$\cite{DS}，以及$Ernesto Jim$\cite{KJ}的$Ontoemma$的基于深度学习的本体匹配方法不仅证明了模型自行选择特征是有效的，并且可以获得更适合的特征，提升本体匹配的效果。以上三种是较为典型的基于深度学习类本体匹配方法，这类方法大多借助字典或者上下文信息作为外部资源，借助深度学习模型，得到单词的词嵌入表示，再利用单词的词嵌入得到概念的向量表示，最终利用向量的语义相似度来判断概念的相似度。虽然基于深度学习的本体匹配方法相比人工特征的方法，可以学到更加合适的特征，提升本体匹配的效果，但现有的方法也有其问题，一方面，单词的词嵌入无法包含概念（概念通常包含多个单词）的结构信息，结构信息的缺失，会影响本体匹配的效果。以医学本体FMA\cite{FMA}与NCI\cite{NCI} 的匹配为例，”Blood Capillary“（NCI中概念）与”Capillary“（FMA中概念）在以上几种基于深度学习本体匹配方法中会被认为是正确匹配（百度翻译也会翻译为同义词”毛细血管“），若考虑结构信息，NCI本体中包含关系”Blood Capillary subclass_of Capillary“，即是“儿子”与”父亲“的关系，则可避免这样的错误。所以，如何引入本体的结构信息进一步提高本体匹配的性能具有重要的现实意义。另一方面，基于深度学习的本体匹配方法的性能依赖于模型所学特征，其常常使用随机向量或者基于文本的预训练模型来提取待匹配概念的特征或表示。但随机向量或者文本预训练模型得到的概念向量表示通常会将概念做为一个独立的单元忽略了概念之间的关联关系。 这导致其表示不符合概念在知识图谱中的表示。近年来知识图谱表示学习模型展现了其在知识表示的优势，但现有的工作证明，在知识图谱表示模型中，概念或者关系的表示非常依赖模型的参数。如何在知识图谱表示学习中找到更好的参数从而改善待匹配概念的表示并提高本体匹配的效果也是需要克服的问题。因此，综上对于本体匹配的研究依然存在以下挑战：

\indent 1.引入第三方字典和上下文做为外部资源来构建待匹配的概念对是本体匹配的常见方法，但引入字典和上下文仅关注待匹配概念对中概念的字面含义，而本体本身的结构信息也包含了大量的语义，会直接影响本体匹配方法的性能（如上例），如何引入本体的结构信息进一步提高本体匹配方法的性能是本体匹配任务的挑战。

\indent 2.本体匹配方法的性能依赖于本体匹配的特征，深度学习方法在一定程度上克服了人工选择特征的问题，其常常使用随机向量或者基于文本的预训练模型来提取待匹配概念的特征或表示。但随机向量或者文本预训练模型得到的概念向量表示通常会将概念做为一个独立的单元忽略了概念之间的关联关系，这导致其表示不符合概念在知识图谱中的表示。近年来知识图谱表示学习模型展现了其在知识表示的优势，但现有的工作证明，在知识图谱表示模型中，概念或者关系的表示非常依赖模型的参数。如何在知识图谱表示学习中找到更好的参数从而改善待匹配概念的表示并提高本体匹配的效果是另一个挑战。

\section{研究内容}
\setcounter{equation}{0}
\songti\xiaosihao{
\begin{figure}[!h]
\centering
\includegraphics[scale=0.6]{framework.jpg}
\caption{本文算法框架}
\label{figl}
\end{figure}
\indent 本文针对以上现有基于深度学习的本体匹配方法存在的两个挑战，设计了如图1.2所示的算法框架，来解决这些挑战，进一步提升本体匹配的效果。针对问题一，本文设计了基于深度学习的本体匹配模型MuitiOM，针对问题二，本文提出了采用HORD算法的表示学习模型的优化框架，并用该算法改进模型MuitiOM的匹配效果。所以，本文的主要工作包含以下两个方面：

\indent 为了在本体表示中融入更多的信息，本文提出了一个利用多视角的方法来提取概念信息，并再利用矩阵投影方法将不同本体的概念投影到同一个超平面进一步提高了本体匹配的效果。相比与现有深度学习的匹配方法只关注本体概念的字面含义，MuitiOM从概念所在本体中的结构、概念的字面信息以及概念所在文本上下文多个视角来获取概念的表示。相对现有深度学习的方法，多视角可以从不同维度对待匹配的概念对进行计算，进而提升了本体匹配的性能，如上例，结构信息可以为匹配对提供更多的上下位约束。

\indent MultiOM使用了多个表示学习模型通过多个视角来提取待匹配概念的特征，在该方法下人工调节多个模型的参数将降低模型训练的效率且无法取得较好的概念表示进而影响最终匹配的性能。为解决该问题，本文首次将黑箱优化和知识图谱表示学习进行结合。在该方法下，通过黑箱优化HORD算法自动调节多个表示学习模型的参数，进一步使得多视角表示学习模型可以学习更好的特征。

\indent 3.在基准数据集上，利用常用的评估指标对模型效果进行评估，并将本文中的模型的效果与其他较新的模型结果进行对比，分析，验证本文工作的有效性。}

\section{文章结构安排}
\setcounter{equation}{0}
\songti\xiaosihao {本文共分为六个章节，本文的结构编排如下：

第一章：一方面，简述本文的研究背景，介绍语义网，进而通过语义网中本体的异构问题，引出本体匹配；另一方面，根据目前的相关研究存在的问题，阐述本文的研究意义，并对本文的具体研究内容进行简述。

第二章：首先详细阐述现有的本体匹配研究的基于语言学特征的方法，基于结构特征的方法，基于外部资源的方法，基于逻辑推理的方法的原理及各自的经典方法，以及对现有经典的本体匹配系统进行综述，然后对以上方法进行总结，其优缺点，再介绍基于深度学习的本体匹配方法，最后对基于深度学习的方法进行总结。

第三章：详细介绍本文的具体研究内容，首先对本章的预备知识，HORD算法，几类表示学习模型，BERT模型进行说明；提出基于多视角的生物医学本体匹配模型，然后介绍基于HORD算法的几类表示学习模型超参数的优化方法。

第四章：利用常用的模型评价指标，标准数据集，在上一章基础上，对三个研究内容进行实验评估，并将实验结果与其他方法作比较，进行分析。

第五章：对本文的工作进行总结，并对未来工作进行展望。

第六章：本文的相关参考文献。}
\ifx\allfiles\undefined
\end{document}
\fi
% ----------------------------------------------------------------
